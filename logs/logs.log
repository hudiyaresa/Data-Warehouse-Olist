2024-12-22 04:53:27,609 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-22 04:53:27,613 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-22 04:53:27,664 - INFO - Extract All Tables From Sources - FAILED
2024-12-22 04:53:27,680 - ERROR - [pid 14734] Worker Worker(salt=1177210169, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=14734) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-22 04:53:27,764 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-22 04:53:27,772 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-22 04:53:27,773 - DEBUG - Asking scheduler for work...
2024-12-22 04:53:27,777 - DEBUG - Done
2024-12-22 04:53:27,777 - DEBUG - There are no more tasks to run at this time
2024-12-22 04:53:27,778 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-12-22 04:53:27,779 - DEBUG - There are 1 pending tasks unique to this worker
2024-12-22 04:53:27,780 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-12-22 04:53:27,780 - INFO - Worker Worker(salt=1177210169, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=14734) was stopped. Shutting down Keep-Alive thread
2024-12-22 04:53:27,782 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 complete ones were encountered:
    - 1 Load()
    - 1 Transform()
* 1 failed:
    - 1 Extract()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-22 21:30:29,437 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-22 21:30:29,442 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-22 21:30:29,493 - INFO - Extract All Tables From Sources - FAILED
2024-12-22 21:30:29,504 - ERROR - [pid 70529] Worker Worker(salt=3783739673, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=70529) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-22 21:30:29,553 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-22 21:30:29,559 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-22 21:30:29,560 - DEBUG - Asking scheduler for work...
2024-12-22 21:30:29,564 - DEBUG - Done
2024-12-22 21:30:29,564 - DEBUG - There are no more tasks to run at this time
2024-12-22 21:30:29,565 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-22 21:30:29,565 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-22 21:30:29,566 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-22 21:30:29,566 - INFO - Worker Worker(salt=3783739673, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=70529) was stopped. Shutting down Keep-Alive thread
2024-12-22 21:30:29,568 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-22 21:31:54,817 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-22 21:31:54,821 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-22 21:31:54,853 - INFO - Extract All Tables From Sources - FAILED
2024-12-22 21:31:54,863 - ERROR - [pid 70885] Worker Worker(salt=6159693716, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=70885) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-22 21:31:54,904 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-22 21:31:54,912 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-22 21:31:54,913 - DEBUG - Asking scheduler for work...
2024-12-22 21:31:54,916 - DEBUG - Done
2024-12-22 21:31:54,916 - DEBUG - There are no more tasks to run at this time
2024-12-22 21:31:54,917 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-22 21:31:54,918 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-22 21:31:54,918 - INFO - Worker Worker(salt=6159693716, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=70885) was stopped. Shutting down Keep-Alive thread
2024-12-22 21:31:54,919 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-22 21:36:39,390 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-22 21:36:39,394 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-22 21:36:39,426 - INFO - Extract All Tables From Sources - FAILED
2024-12-22 21:36:39,435 - ERROR - [pid 72020] Worker Worker(salt=1865527980, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=72020) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-22 21:36:39,499 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-22 21:36:39,506 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-22 21:36:39,506 - DEBUG - Asking scheduler for work...
2024-12-22 21:36:39,509 - DEBUG - Done
2024-12-22 21:36:39,509 - DEBUG - There are no more tasks to run at this time
2024-12-22 21:36:39,510 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-22 21:36:39,510 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-22 21:36:39,511 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-22 21:36:39,511 - INFO - Worker Worker(salt=1865527980, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=72020) was stopped. Shutting down Keep-Alive thread
2024-12-22 21:36:39,512 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-22 21:49:04,250 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-22 21:49:04,254 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-22 21:49:04,306 - INFO - Extract All Tables From Sources - FAILED
2024-12-22 21:49:04,315 - ERROR - [pid 77395] Worker Worker(salt=3111333868, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=77395) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-22 21:49:04,367 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-22 21:49:04,372 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-22 21:49:04,372 - DEBUG - Asking scheduler for work...
2024-12-22 21:49:04,374 - DEBUG - Done
2024-12-22 21:49:04,375 - DEBUG - There are no more tasks to run at this time
2024-12-22 21:49:04,375 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-22 21:49:04,376 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-22 21:49:04,376 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-22 21:49:04,377 - INFO - Worker Worker(salt=3111333868, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=77395) was stopped. Shutting down Keep-Alive thread
2024-12-22 21:49:04,378 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-22 21:54:54,907 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-22 21:54:54,913 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-22 21:54:54,958 - INFO - Extract All Tables From Sources - FAILED
2024-12-22 21:54:54,968 - ERROR - [pid 78994] Worker Worker(salt=7983099728, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=78994) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-22 21:54:55,018 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-22 21:54:55,024 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-22 21:54:55,025 - DEBUG - Asking scheduler for work...
2024-12-22 21:54:55,027 - DEBUG - Done
2024-12-22 21:54:55,027 - DEBUG - There are no more tasks to run at this time
2024-12-22 21:54:55,028 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-22 21:54:55,028 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-22 21:54:55,029 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-22 21:54:55,029 - INFO - Worker Worker(salt=7983099728, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=78994) was stopped. Shutting down Keep-Alive thread
2024-12-22 21:54:55,030 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-22 22:27:26,264 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-22 22:27:26,269 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-22 22:27:26,306 - INFO - Extract All Tables From Sources - FAILED
2024-12-22 22:27:26,316 - ERROR - [pid 86740] Worker Worker(salt=2129863596, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=86740) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-22 22:27:26,370 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-22 22:27:26,375 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-22 22:27:26,376 - DEBUG - Asking scheduler for work...
2024-12-22 22:27:26,378 - DEBUG - Done
2024-12-22 22:27:26,379 - DEBUG - There are no more tasks to run at this time
2024-12-22 22:27:26,379 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-22 22:27:26,380 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-22 22:27:26,380 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-22 22:27:26,380 - INFO - Worker Worker(salt=2129863596, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=86740) was stopped. Shutting down Keep-Alive thread
2024-12-22 22:27:26,382 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-22 22:28:54,427 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-22 22:28:54,432 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-22 22:28:54,470 - INFO - Extract All Tables From Sources - FAILED
2024-12-22 22:28:54,483 - ERROR - [pid 87106] Worker Worker(salt=5297958816, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=87106) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-22 22:28:54,533 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-22 22:28:54,540 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-22 22:28:54,541 - DEBUG - Asking scheduler for work...
2024-12-22 22:28:54,543 - DEBUG - Done
2024-12-22 22:28:54,544 - DEBUG - There are no more tasks to run at this time
2024-12-22 22:28:54,546 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-22 22:28:54,546 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-22 22:28:54,547 - INFO - Worker Worker(salt=5297958816, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=87106) was stopped. Shutting down Keep-Alive thread
2024-12-22 22:28:54,549 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-22 22:29:25,624 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-22 22:29:25,628 - ERROR - EXTRACT 'public.products' - FAILED.
2024-12-22 22:29:25,659 - INFO - Extract All Tables From Sources - FAILED
2024-12-22 22:29:25,667 - ERROR - [pid 87248] Worker Worker(salt=4436780551, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=87248) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.products' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-22 22:29:25,707 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-22 22:29:25,713 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-22 22:29:25,714 - DEBUG - Asking scheduler for work...
2024-12-22 22:29:25,717 - DEBUG - Done
2024-12-22 22:29:25,717 - DEBUG - There are no more tasks to run at this time
2024-12-22 22:29:25,718 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-22 22:29:25,719 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-22 22:29:25,719 - INFO - Worker Worker(salt=4436780551, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=87248) was stopped. Shutting down Keep-Alive thread
2024-12-22 22:29:25,721 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-22 23:32:32,261 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-22 23:32:32,269 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-22 23:32:32,309 - INFO - Extract All Tables From Sources - FAILED
2024-12-22 23:32:32,322 - ERROR - [pid 102232] Worker Worker(salt=593273724, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=102232) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-22 23:32:32,383 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-22 23:32:32,389 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-22 23:32:32,390 - DEBUG - Asking scheduler for work...
2024-12-22 23:32:32,393 - DEBUG - Done
2024-12-22 23:32:32,394 - DEBUG - There are no more tasks to run at this time
2024-12-22 23:32:32,395 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-22 23:32:32,395 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-22 23:32:32,396 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-22 23:32:32,396 - INFO - Worker Worker(salt=593273724, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=102232) was stopped. Shutting down Keep-Alive thread
2024-12-22 23:32:32,398 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-22 23:55:26,218 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-22 23:55:26,223 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-22 23:55:26,293 - INFO - Extract All Tables From Sources - FAILED
2024-12-22 23:55:26,303 - ERROR - [pid 114574] Worker Worker(salt=743511585, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=114574) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-22 23:55:26,351 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-22 23:55:26,357 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-22 23:55:26,358 - DEBUG - Asking scheduler for work...
2024-12-22 23:55:26,360 - DEBUG - Done
2024-12-22 23:55:26,361 - DEBUG - There are no more tasks to run at this time
2024-12-22 23:55:26,361 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-22 23:55:26,362 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-22 23:55:26,363 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-22 23:55:26,363 - INFO - Worker Worker(salt=743511585, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=114574) was stopped. Shutting down Keep-Alive thread
2024-12-22 23:55:26,366 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-22 23:57:46,629 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-22 23:57:46,633 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-22 23:57:46,683 - INFO - Extract All Tables From Sources - FAILED
2024-12-22 23:57:46,690 - ERROR - [pid 114603] Worker Worker(salt=1478653978, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=114603) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-22 23:57:46,737 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-22 23:57:46,744 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-22 23:57:46,745 - DEBUG - Asking scheduler for work...
2024-12-22 23:57:46,748 - DEBUG - Done
2024-12-22 23:57:46,748 - DEBUG - There are no more tasks to run at this time
2024-12-22 23:57:46,748 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-22 23:57:46,748 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-22 23:57:46,749 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-22 23:57:46,749 - INFO - Worker Worker(salt=1478653978, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=114603) was stopped. Shutting down Keep-Alive thread
2024-12-22 23:57:46,750 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-23 00:11:35,397 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-23 00:11:35,401 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-23 00:11:35,478 - INFO - Extract All Tables From Sources - FAILED
2024-12-23 00:11:35,488 - ERROR - [pid 114781] Worker Worker(salt=7395089440, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=114781) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-23 00:11:35,533 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-23 00:11:35,539 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-23 00:11:35,540 - DEBUG - Asking scheduler for work...
2024-12-23 00:11:35,542 - DEBUG - Done
2024-12-23 00:11:35,543 - DEBUG - There are no more tasks to run at this time
2024-12-23 00:11:35,543 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-23 00:11:35,544 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-23 00:11:35,544 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-23 00:11:35,544 - INFO - Worker Worker(salt=7395089440, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=114781) was stopped. Shutting down Keep-Alive thread
2024-12-23 00:11:35,546 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-23 00:16:54,447 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-23 00:16:54,450 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-23 00:16:54,494 - INFO - Extract All Tables From Sources - FAILED
2024-12-23 00:16:54,500 - ERROR - [pid 114808] Worker Worker(salt=9939307206, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=114808) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-23 00:16:54,537 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-23 00:16:54,544 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-23 00:16:54,545 - DEBUG - Asking scheduler for work...
2024-12-23 00:16:54,548 - DEBUG - Done
2024-12-23 00:16:54,548 - DEBUG - There are no more tasks to run at this time
2024-12-23 00:16:54,549 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-23 00:16:54,549 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-23 00:16:54,549 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-23 00:16:54,550 - INFO - Worker Worker(salt=9939307206, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=114808) was stopped. Shutting down Keep-Alive thread
2024-12-23 00:16:54,551 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-23 00:19:54,708 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-23 00:19:54,710 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-23 00:19:54,753 - INFO - Extract All Tables From Sources - FAILED
2024-12-23 00:19:54,762 - ERROR - [pid 114917] Worker Worker(salt=9277330010, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=114917) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-23 00:19:54,805 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-23 00:19:54,810 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-23 00:19:54,811 - DEBUG - Asking scheduler for work...
2024-12-23 00:19:54,813 - DEBUG - Done
2024-12-23 00:19:54,813 - DEBUG - There are no more tasks to run at this time
2024-12-23 00:19:54,814 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-23 00:19:54,814 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-23 00:19:54,814 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-23 00:19:54,815 - INFO - Worker Worker(salt=9277330010, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=114917) was stopped. Shutting down Keep-Alive thread
2024-12-23 00:19:54,816 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-23 01:44:22,767 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-23 01:44:22,798 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-23 01:44:22,874 - INFO - Extract All Tables From Sources - FAILED
2024-12-23 01:44:22,892 - ERROR - [pid 472] Worker Worker(salt=989016694, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=472) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5440 failed: FATAL:  password authentication failed for user "postgres"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5440 failed: FATAL:  password authentication failed for user "postgres"

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-23 01:44:22,981 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-23 01:44:22,989 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-23 01:44:22,990 - DEBUG - Asking scheduler for work...
2024-12-23 01:44:22,993 - DEBUG - Done
2024-12-23 01:44:22,994 - DEBUG - There are no more tasks to run at this time
2024-12-23 01:44:22,994 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-23 01:44:22,995 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-23 01:44:22,996 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-23 01:44:22,997 - INFO - Worker Worker(salt=989016694, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=472) was stopped. Shutting down Keep-Alive thread
2024-12-23 01:44:23,001 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-23 01:45:09,651 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-23 01:45:09,674 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-23 01:45:09,782 - INFO - Extract All Tables From Sources - FAILED
2024-12-23 01:45:09,798 - ERROR - [pid 497] Worker Worker(salt=9835193611, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=497) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5440 failed: FATAL:  database "olist" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3279, in connect
    return self._connection_cls(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 147, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2443, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 145, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3303, in raw_connection
    return self.pool.connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 616, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/user/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5440 failed: FATAL:  database "olist" does not exist

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-23 01:45:09,877 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-23 01:45:09,883 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-23 01:45:09,884 - DEBUG - Asking scheduler for work...
2024-12-23 01:45:09,888 - DEBUG - Done
2024-12-23 01:45:09,888 - DEBUG - There are no more tasks to run at this time
2024-12-23 01:45:09,889 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-23 01:45:09,890 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-23 01:45:09,891 - INFO - Worker Worker(salt=9835193611, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=497) was stopped. Shutting down Keep-Alive thread
2024-12-23 01:45:09,892 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-23 01:45:46,211 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-23 01:45:46,269 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-23 01:45:46,318 - INFO - Extract All Tables From Sources - FAILED
2024-12-23 01:45:46,328 - ERROR - [pid 516] Worker Worker(salt=874655761, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=516) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "public.customers" does not exist
LINE 1: SELECT * FROM public.customers;
                      ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 526, in read_sql_query
    return pandas_sql.read_query(
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1836, in read_query
    result = self.execute(sql, params)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1659, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1782, in exec_driver_sql
    ret = self._execute_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "public.customers" does not exist
LINE 1: SELECT * FROM public.customers;
                      ^

[SQL: SELECT * FROM public.customers;]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-23 01:45:46,380 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-23 01:45:46,386 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-23 01:45:46,387 - DEBUG - Asking scheduler for work...
2024-12-23 01:45:46,391 - DEBUG - Done
2024-12-23 01:45:46,392 - DEBUG - There are no more tasks to run at this time
2024-12-23 01:45:46,393 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-23 01:45:46,393 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-23 01:45:46,394 - INFO - Worker Worker(salt=874655761, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=516) was stopped. Shutting down Keep-Alive thread
2024-12-23 01:45:46,396 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-12-23 02:59:27,881 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-12-23 02:59:27,931 - ERROR - EXTRACT 'public.customers' - FAILED.
2024-12-23 02:59:27,987 - INFO - Extract All Tables From Sources - FAILED
2024-12-23 02:59:27,997 - ERROR - [pid 787] Worker Worker(salt=2783360370, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=787) failed    Extract()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "public.customers" does not exist
LINE 1: SELECT * FROM public.customers;
                      ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 56, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 526, in read_sql_query
    return pandas_sql.read_query(
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1836, in read_query
    result = self.execute(sql, params)
  File "/home/user/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1659, in execute
    return self.con.exec_driver_sql(sql, *args)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1782, in exec_driver_sql
    ret = self._execute_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "public.customers" does not exist
LINE 1: SELECT * FROM public.customers;
                      ^

[SQL: SELECT * FROM public.customers;]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 65, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.customers' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/extract.py", line 104, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-12-23 02:59:28,045 - DEBUG - 1 running tasks, waiting for next task to finish
2024-12-23 02:59:28,051 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-12-23 02:59:28,052 - DEBUG - Asking scheduler for work...
2024-12-23 02:59:28,054 - DEBUG - Done
2024-12-23 02:59:28,054 - DEBUG - There are no more tasks to run at this time
2024-12-23 02:59:28,054 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-12-23 02:59:28,055 - DEBUG - There are 3 pending tasks unique to this worker
2024-12-23 02:59:28,055 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-12-23 02:59:28,055 - INFO - Worker Worker(salt=2783360370, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=787) was stopped. Shutting down Keep-Alive thread
2024-12-23 02:59:28,056 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-10 02:51:06,727 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-10 02:51:06,861 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-10 02:51:07,358 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-10 02:51:07,386 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-10 02:51:08,287 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-10 02:51:08,752 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-10 02:51:09,419 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-10 02:51:10,222 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-10 02:51:10,248 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-10 02:51:10,508 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-10 02:51:10,509 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-10 02:51:10,514 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-10 02:51:10,515 - INFO - [pid 1325] Worker Worker(salt=6183284721, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1325) done      Extract()
2025-01-10 02:51:10,516 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 02:51:10,519 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-10 02:51:10,520 - DEBUG - Asking scheduler for work...
2025-01-10 02:51:10,523 - DEBUG - Pending tasks: 2
2025-01-10 02:51:10,523 - INFO - [pid 1325] Worker Worker(salt=6183284721, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1325) running   Load()
2025-01-10 02:51:10,543 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE ;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-10 02:51:11,777 - INFO - Read Extracted Data - SUCCESS
2025-01-10 02:51:11,779 - INFO - Connect to DWH - SUCCESS
2025-01-10 02:51:11,811 - ERROR - Truncate sources Schema in DWH - FAILED
2025-01-10 02:51:11,813 - ERROR - [pid 1325] Worker Worker(salt=6183284721, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1325) failed    Load()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "public.customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 133, in run
    session.execute(query)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "public.customers" does not exist

[SQL: TRUNCATE TABLE public.customers CASCADE]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 144, in run
    raise Exception("Failed to Truncate sources Schema in DWH")
Exception: Failed to Truncate sources Schema in DWH
2025-01-10 02:51:11,836 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 02:51:11,841 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2025-01-10 02:51:11,842 - DEBUG - Asking scheduler for work...
2025-01-10 02:51:11,844 - DEBUG - Done
2025-01-10 02:51:11,844 - DEBUG - There are no more tasks to run at this time
2025-01-10 02:51:11,845 - DEBUG - There are 2 pending tasks possibly being run by other workers
2025-01-10 02:51:11,846 - DEBUG - There are 2 pending tasks unique to this worker
2025-01-10 02:51:11,846 - DEBUG - There are 2 pending tasks last scheduled by this worker
2025-01-10 02:51:11,847 - INFO - Worker Worker(salt=6183284721, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1325) was stopped. Shutting down Keep-Alive thread
2025-01-10 02:51:11,848 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-10 02:52:45,035 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-10 02:52:45,158 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-10 02:52:45,682 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-10 02:52:45,708 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-10 02:52:46,581 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-10 02:52:46,994 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-10 02:52:47,722 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-10 02:52:48,631 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-10 02:52:48,660 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-10 02:52:48,923 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-10 02:52:48,924 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-10 02:52:48,930 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-10 02:52:48,931 - INFO - [pid 1346] Worker Worker(salt=3119685047, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1346) done      Extract()
2025-01-10 02:52:48,933 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 02:52:48,936 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-10 02:52:48,937 - DEBUG - Asking scheduler for work...
2025-01-10 02:52:48,940 - DEBUG - Pending tasks: 2
2025-01-10 02:52:48,940 - INFO - [pid 1346] Worker Worker(salt=3119685047, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1346) running   Load()
2025-01-10 02:52:48,966 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-10 02:52:50,126 - INFO - Read Extracted Data - SUCCESS
2025-01-10 02:52:50,128 - INFO - Connect to DWH - SUCCESS
2025-01-10 02:52:50,143 - ERROR - Truncate sources Schema in DWH - FAILED
2025-01-10 02:52:50,145 - ERROR - [pid 1346] Worker Worker(salt=3119685047, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1346) failed    Load()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "public.customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 133, in run
    session.execute(query)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "public.customers" does not exist

[SQL: TRUNCATE TABLE public.customers CASCADE]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 144, in run
    raise Exception("Failed to Truncate sources Schema in DWH")
Exception: Failed to Truncate sources Schema in DWH
2025-01-10 02:52:50,169 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 02:52:50,174 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2025-01-10 02:52:50,174 - DEBUG - Asking scheduler for work...
2025-01-10 02:52:50,176 - DEBUG - Done
2025-01-10 02:52:50,177 - DEBUG - There are no more tasks to run at this time
2025-01-10 02:52:50,177 - DEBUG - There are 2 pending tasks possibly being run by other workers
2025-01-10 02:52:50,178 - DEBUG - There are 2 pending tasks unique to this worker
2025-01-10 02:52:50,178 - DEBUG - There are 2 pending tasks last scheduled by this worker
2025-01-10 02:52:50,179 - INFO - Worker Worker(salt=3119685047, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1346) was stopped. Shutting down Keep-Alive thread
2025-01-10 02:52:50,180 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-10 02:54:48,527 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-10 02:54:48,656 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-10 02:54:49,243 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-10 02:54:49,273 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-10 02:54:50,259 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-10 02:54:50,691 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-10 02:54:51,338 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-10 02:54:52,221 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-10 02:54:52,252 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-10 02:54:52,495 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-10 02:54:52,496 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-10 02:54:52,502 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-10 02:54:52,503 - INFO - [pid 1367] Worker Worker(salt=2103284914, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1367) done      Extract()
2025-01-10 02:54:52,504 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 02:54:52,508 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-10 02:54:52,508 - DEBUG - Asking scheduler for work...
2025-01-10 02:54:52,511 - DEBUG - Pending tasks: 2
2025-01-10 02:54:52,511 - INFO - [pid 1367] Worker Worker(salt=2103284914, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1367) running   Load()
2025-01-10 02:54:52,526 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-10 02:54:53,706 - INFO - Read Extracted Data - SUCCESS
2025-01-10 02:54:53,707 - INFO - Connect to DWH - SUCCESS
2025-01-10 02:54:53,719 - ERROR - Truncate sources Schema in DWH - FAILED
2025-01-10 02:54:53,721 - ERROR - [pid 1367] Worker Worker(salt=2103284914, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1367) failed    Load()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "public.customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 133, in run
    session.execute(query)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "public.customers" does not exist

[SQL: TRUNCATE TABLE public.customers CASCADE]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 145, in run
    raise Exception("Failed to Truncate sources Schema in DWH")
Exception: Failed to Truncate sources Schema in DWH
2025-01-10 02:54:53,744 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 02:54:53,749 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2025-01-10 02:54:53,750 - DEBUG - Asking scheduler for work...
2025-01-10 02:54:53,753 - DEBUG - Done
2025-01-10 02:54:53,754 - DEBUG - There are no more tasks to run at this time
2025-01-10 02:54:53,754 - DEBUG - There are 2 pending tasks possibly being run by other workers
2025-01-10 02:54:53,755 - DEBUG - There are 2 pending tasks unique to this worker
2025-01-10 02:54:53,755 - DEBUG - There are 2 pending tasks last scheduled by this worker
2025-01-10 02:54:53,755 - INFO - Worker Worker(salt=2103284914, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1367) was stopped. Shutting down Keep-Alive thread
2025-01-10 02:54:53,756 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-10 03:01:09,138 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-10 03:01:09,239 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-10 03:01:09,763 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-10 03:01:09,793 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-10 03:01:10,659 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-10 03:01:11,223 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-10 03:01:11,939 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-10 03:01:12,944 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-10 03:01:12,974 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-10 03:01:13,240 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-10 03:01:13,242 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-10 03:01:13,248 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-10 03:01:13,250 - INFO - [pid 1400] Worker Worker(salt=7550346014, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1400) done      Extract()
2025-01-10 03:01:13,251 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 03:01:13,256 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-10 03:01:13,257 - DEBUG - Asking scheduler for work...
2025-01-10 03:01:13,259 - DEBUG - Pending tasks: 2
2025-01-10 03:01:13,260 - INFO - [pid 1400] Worker Worker(salt=7550346014, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1400) running   Load()
2025-01-10 03:01:13,278 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-10 03:01:14,463 - INFO - Read Extracted Data - SUCCESS
2025-01-10 03:01:14,465 - INFO - Connect to DWH - SUCCESS
2025-01-10 03:01:14,477 - ERROR - Truncate sources Schema in DWH - FAILED
2025-01-10 03:01:14,479 - ERROR - [pid 1400] Worker Worker(salt=7550346014, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1400) failed    Load()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "public.customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 133, in run
    session.execute(query)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "public.customers" does not exist

[SQL: TRUNCATE TABLE public.customers CASCADE]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 144, in run
    raise Exception("Failed to Truncate sources Schema in DWH")
Exception: Failed to Truncate sources Schema in DWH
2025-01-10 03:01:14,504 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 03:01:14,509 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2025-01-10 03:01:14,510 - DEBUG - Asking scheduler for work...
2025-01-10 03:01:14,512 - DEBUG - Done
2025-01-10 03:01:14,512 - DEBUG - There are no more tasks to run at this time
2025-01-10 03:01:14,513 - DEBUG - There are 2 pending tasks possibly being run by other workers
2025-01-10 03:01:14,513 - DEBUG - There are 2 pending tasks unique to this worker
2025-01-10 03:01:14,513 - DEBUG - There are 2 pending tasks last scheduled by this worker
2025-01-10 03:01:14,514 - INFO - Worker Worker(salt=7550346014, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1400) was stopped. Shutting down Keep-Alive thread
2025-01-10 03:01:14,515 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-10 03:02:34,897 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-10 03:02:35,010 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-10 03:02:35,573 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-10 03:02:35,600 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-10 03:02:36,545 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-10 03:02:36,995 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-10 03:02:37,685 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-10 03:02:38,591 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-10 03:02:38,625 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-10 03:02:38,888 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-10 03:02:38,889 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-10 03:02:38,895 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-10 03:02:38,896 - INFO - [pid 1421] Worker Worker(salt=4499232462, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1421) done      Extract()
2025-01-10 03:02:38,898 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 03:02:38,902 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-10 03:02:38,902 - DEBUG - Asking scheduler for work...
2025-01-10 03:02:38,905 - DEBUG - Pending tasks: 2
2025-01-10 03:02:38,906 - INFO - [pid 1421] Worker Worker(salt=4499232462, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1421) running   Load()
2025-01-10 03:02:38,921 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-10 03:02:40,017 - INFO - Read Extracted Data - SUCCESS
2025-01-10 03:02:40,018 - INFO - Connect to DWH - SUCCESS
2025-01-10 03:02:40,030 - ERROR - Truncate sources Schema in DWH - FAILED
2025-01-10 03:02:40,032 - ERROR - [pid 1421] Worker Worker(salt=4499232462, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1421) failed    Load()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "public.customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 133, in run
    session.execute(query)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "public.customers" does not exist

[SQL: TRUNCATE TABLE public.customers CASCADE]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 144, in run
    raise Exception("Failed to Truncate sources Schema in DWH")
Exception: Failed to Truncate sources Schema in DWH
2025-01-10 03:02:40,053 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 03:02:40,057 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2025-01-10 03:02:40,057 - DEBUG - Asking scheduler for work...
2025-01-10 03:02:40,059 - DEBUG - Done
2025-01-10 03:02:40,060 - DEBUG - There are no more tasks to run at this time
2025-01-10 03:02:40,060 - DEBUG - There are 2 pending tasks possibly being run by other workers
2025-01-10 03:02:40,060 - DEBUG - There are 2 pending tasks unique to this worker
2025-01-10 03:02:40,061 - DEBUG - There are 2 pending tasks last scheduled by this worker
2025-01-10 03:02:40,061 - INFO - Worker Worker(salt=4499232462, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1421) was stopped. Shutting down Keep-Alive thread
2025-01-10 03:02:40,063 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-10 03:09:35,020 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-10 03:09:35,132 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-10 03:09:35,674 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-10 03:09:35,710 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-10 03:09:36,651 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-10 03:09:37,098 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-10 03:09:37,827 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-10 03:09:38,833 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-10 03:09:38,865 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-10 03:09:39,111 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-10 03:09:39,113 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-10 03:09:39,120 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-10 03:09:39,121 - INFO - [pid 1451] Worker Worker(salt=222051670, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1451) done      Extract()
2025-01-10 03:09:39,123 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 03:09:39,126 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-10 03:09:39,126 - DEBUG - Asking scheduler for work...
2025-01-10 03:09:39,130 - DEBUG - Pending tasks: 2
2025-01-10 03:09:39,131 - INFO - [pid 1451] Worker Worker(salt=222051670, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1451) running   Load()
2025-01-10 03:09:39,152 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-10 03:09:40,357 - INFO - Read Extracted Data - SUCCESS
2025-01-10 03:09:40,358 - INFO - Connect to DWH - SUCCESS
2025-01-10 03:09:40,371 - ERROR - Truncate sources Schema in DWH - FAILED
2025-01-10 03:09:40,373 - ERROR - [pid 1451] Worker Worker(salt=222051670, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1451) failed    Load()
Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedTable: relation "public.customers" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 133, in run
    session.execute(query)
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/home/user/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "public.customers" does not exist

[SQL: TRUNCATE TABLE public.customers CASCADE]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/user/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 144, in run
    raise Exception("Failed to Truncate sources Schema in DWH")
Exception: Failed to Truncate sources Schema in DWH
2025-01-10 03:09:40,398 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 03:09:40,402 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2025-01-10 03:09:40,402 - DEBUG - Asking scheduler for work...
2025-01-10 03:09:40,405 - DEBUG - Done
2025-01-10 03:09:40,405 - DEBUG - There are no more tasks to run at this time
2025-01-10 03:09:40,406 - DEBUG - There are 2 pending tasks possibly being run by other workers
2025-01-10 03:09:40,406 - DEBUG - There are 2 pending tasks unique to this worker
2025-01-10 03:09:40,406 - DEBUG - There are 2 pending tasks last scheduled by this worker
2025-01-10 03:09:40,407 - INFO - Worker Worker(salt=222051670, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1451) was stopped. Shutting down Keep-Alive thread
2025-01-10 03:09:40,409 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-10 11:17:13,116 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-10 11:17:13,471 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-10 11:17:14,395 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-10 11:17:14,438 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-10 11:17:16,033 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-10 11:17:16,881 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-10 11:17:18,245 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-10 11:17:19,623 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-10 11:17:19,653 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-10 11:17:20,056 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-10 11:17:20,057 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-10 11:17:20,089 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-10 11:17:20,091 - INFO - [pid 1720] Worker Worker(salt=8882184260, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1720) done      Extract()
2025-01-10 11:17:20,092 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 11:17:20,096 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-10 11:17:20,098 - DEBUG - Asking scheduler for work...
2025-01-10 11:17:20,101 - DEBUG - Pending tasks: 2
2025-01-10 11:17:20,102 - INFO - [pid 1720] Worker Worker(salt=8882184260, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1720) running   Load()
2025-01-10 11:17:20,153 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-10 11:17:22,340 - INFO - Read Extracted Data - SUCCESS
2025-01-10 11:17:22,342 - INFO - Connect to DWH - SUCCESS
2025-01-10 11:17:22,407 - INFO - Truncate sources Schema in DWH - SUCCESS
2025-01-10 11:17:22,408 - INFO - ==================================STARTING LOAD DATA=======================================
2025-01-10 11:17:22,807 - INFO - LOAD 'public.geolocation' - SUCCESS
2025-01-10 11:17:22,823 - INFO - LOAD 'public.product_category_name_translation' - SUCCESS
2025-01-10 11:17:24,955 - INFO - LOAD 'public.customers' - SUCCESS
2025-01-10 11:17:25,006 - INFO - LOAD 'public.sellers' - SUCCESS
2025-01-10 11:17:26,200 - INFO - LOAD 'public.products' - SUCCESS
2025-01-10 11:17:28,901 - INFO - LOAD 'public.orders' - SUCCESS
2025-01-10 11:17:31,953 - INFO - LOAD 'public.order_items' - SUCCESS
2025-01-10 11:17:34,020 - INFO - LOAD 'public.order_payments' - SUCCESS
2025-01-10 11:17:38,067 - INFO - LOAD 'public.order_reviews' - SUCCESS
2025-01-10 11:17:38,068 - INFO - LOAD All Tables To DWH-public - SUCCESS
2025-01-10 11:17:38,190 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2025-01-10 11:17:38,205 - ERROR - LOAD All Tables To DWH - FAILED
2025-01-10 11:17:38,213 - ERROR - [pid 1720] Worker Worker(salt=8882184260, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1720) failed    Load()
Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column customers.updated_at does not exist
LINE 28:                         stg.customers.updated_at
                                 ^
HINT:  Perhaps you meant to reference the column "customers.created_at".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 255, in run
    session.execute(query)
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column customers.updated_at does not exist
LINE 28:                         stg.customers.updated_at
                                 ^
HINT:  Perhaps you meant to reference the column "customers.created_at".

[SQL: INSERT INTO stg.customers 
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id,
    customer_unique_id,
    customer_zip_code_prefix,
    customer_city,
    customer_state

FROM public.customers

ON CONFLICT(customer_id) 
DO UPDATE SET
    customer_unique_id = EXCLUDED.customer_unique_id,
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,

    updated_at = CASE WHEN 
                        stg.customers.customer_unique_id <> EXCLUDED.customer_unique_id 
                        OR stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix 
                        OR stg.customers.customer_city <> EXCLUDED.customer_city 
                        OR stg.customers.customer_state <> EXCLUDED.customer_state 
                THEN
                        CURRENT_TIMESTAMP
                ELSE
                        stg.customers.updated_at
                END;]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 265, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 304, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2025-01-10 11:17:38,506 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 11:17:38,512 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2025-01-10 11:17:38,513 - DEBUG - Asking scheduler for work...
2025-01-10 11:17:38,515 - DEBUG - Done
2025-01-10 11:17:38,516 - DEBUG - There are no more tasks to run at this time
2025-01-10 11:17:38,516 - DEBUG - There are 2 pending tasks possibly being run by other workers
2025-01-10 11:17:38,517 - DEBUG - There are 2 pending tasks unique to this worker
2025-01-10 11:17:38,517 - DEBUG - There are 2 pending tasks last scheduled by this worker
2025-01-10 11:17:38,518 - INFO - Worker Worker(salt=8882184260, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1720) was stopped. Shutting down Keep-Alive thread
2025-01-10 11:17:38,519 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-10 12:38:36,917 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-10 12:38:37,153 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-10 12:38:38,061 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-10 12:38:38,103 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-10 12:38:39,666 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-10 12:38:40,268 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-10 12:38:41,657 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-10 12:38:43,267 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-10 12:38:43,299 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-10 12:38:43,666 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-10 12:38:43,667 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-10 12:38:43,697 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-10 12:38:43,698 - INFO - [pid 1954] Worker Worker(salt=1031136554, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1954) done      Extract()
2025-01-10 12:38:43,700 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 12:38:43,704 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-10 12:38:43,705 - DEBUG - Asking scheduler for work...
2025-01-10 12:38:43,708 - DEBUG - Pending tasks: 2
2025-01-10 12:38:43,709 - INFO - [pid 1954] Worker Worker(salt=1031136554, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1954) running   Load()
2025-01-10 12:38:43,744 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-10 12:38:45,867 - INFO - Read Extracted Data - SUCCESS
2025-01-10 12:38:45,868 - INFO - Connect to DWH - SUCCESS
2025-01-10 12:38:45,959 - INFO - Truncate sources Schema in DWH - SUCCESS
2025-01-10 12:38:45,960 - INFO - ==================================STARTING LOAD DATA=======================================
2025-01-10 12:38:46,354 - INFO - LOAD 'public.geolocation' - SUCCESS
2025-01-10 12:38:46,364 - INFO - LOAD 'public.product_category_name_translation' - SUCCESS
2025-01-10 12:38:48,171 - INFO - LOAD 'public.customers' - SUCCESS
2025-01-10 12:38:48,218 - INFO - LOAD 'public.sellers' - SUCCESS
2025-01-10 12:38:49,400 - INFO - LOAD 'public.products' - SUCCESS
2025-01-10 12:38:51,922 - INFO - LOAD 'public.orders' - SUCCESS
2025-01-10 12:38:54,669 - INFO - LOAD 'public.order_items' - SUCCESS
2025-01-10 12:38:56,555 - INFO - LOAD 'public.order_payments' - SUCCESS
2025-01-10 12:38:58,715 - INFO - LOAD 'public.order_reviews' - SUCCESS
2025-01-10 12:38:58,716 - INFO - LOAD All Tables To DWH-public - SUCCESS
2025-01-10 12:38:59,710 - ERROR - LOAD All Tables To DWH-Staging - FAILED
2025-01-10 12:38:59,723 - ERROR - LOAD All Tables To DWH - FAILED
2025-01-10 12:38:59,729 - ERROR - [pid 1954] Worker Worker(salt=1031136554, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1954) failed    Load()
Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column customers.updated_at does not exist
LINE 28:                         stg.customers.updated_at
                                 ^
HINT:  Perhaps you meant to reference the column "customers.created_at".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 255, in run
    session.execute(query)
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column customers.updated_at does not exist
LINE 28:                         stg.customers.updated_at
                                 ^
HINT:  Perhaps you meant to reference the column "customers.created_at".

[SQL: INSERT INTO stg.customers 
    (customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state)

SELECT
    customer_id,
    customer_unique_id,
    customer_zip_code_prefix,
    customer_city,
    customer_state

FROM public.customers

ON CONFLICT(customer_id) 
DO UPDATE SET
    customer_unique_id = EXCLUDED.customer_unique_id,
    customer_zip_code_prefix = EXCLUDED.customer_zip_code_prefix,
    customer_city = EXCLUDED.customer_city,
    customer_state = EXCLUDED.customer_state,

    updated_at = CASE WHEN 
                        stg.customers.customer_unique_id <> EXCLUDED.customer_unique_id 
                        OR stg.customers.customer_zip_code_prefix <> EXCLUDED.customer_zip_code_prefix 
                        OR stg.customers.customer_city <> EXCLUDED.customer_city 
                        OR stg.customers.customer_state <> EXCLUDED.customer_state 
                THEN
                        CURRENT_TIMESTAMP
                ELSE
                        stg.customers.updated_at
                END;]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 265, in run
    raise Exception('Failed Load Tables To DWH-Staging')
Exception: Failed Load Tables To DWH-Staging

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/load.py", line 304, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2025-01-10 12:38:59,853 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 12:38:59,858 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2025-01-10 12:38:59,858 - DEBUG - Asking scheduler for work...
2025-01-10 12:38:59,861 - DEBUG - Done
2025-01-10 12:38:59,861 - DEBUG - There are no more tasks to run at this time
2025-01-10 12:38:59,861 - DEBUG - There are 2 pending tasks possibly being run by other workers
2025-01-10 12:38:59,861 - DEBUG - There are 2 pending tasks unique to this worker
2025-01-10 12:38:59,862 - DEBUG - There are 2 pending tasks last scheduled by this worker
2025-01-10 12:38:59,862 - INFO - Worker Worker(salt=1031136554, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1954) was stopped. Shutting down Keep-Alive thread
2025-01-10 12:38:59,864 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-10 12:47:36,483 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-10 12:47:36,831 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-10 12:47:37,731 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-10 12:47:37,771 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-10 12:47:39,190 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-10 12:47:39,883 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-10 12:47:40,860 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-10 12:47:42,276 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-10 12:47:42,311 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-10 12:47:42,678 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-10 12:47:42,679 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-10 12:47:42,698 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-10 12:47:42,700 - INFO - [pid 1991] Worker Worker(salt=7351372528, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1991) done      Extract()
2025-01-10 12:47:42,701 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 12:47:42,704 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-10 12:47:42,705 - DEBUG - Asking scheduler for work...
2025-01-10 12:47:42,708 - DEBUG - Pending tasks: 2
2025-01-10 12:47:42,709 - INFO - [pid 1991] Worker Worker(salt=7351372528, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1991) running   Load()
2025-01-10 12:47:42,747 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-10 12:47:44,706 - INFO - Read Extracted Data - SUCCESS
2025-01-10 12:47:44,707 - INFO - Connect to DWH - SUCCESS
2025-01-10 12:47:44,794 - INFO - Truncate sources Schema in DWH - SUCCESS
2025-01-10 12:47:44,795 - INFO - ==================================STARTING LOAD DATA=======================================
2025-01-10 12:47:45,180 - INFO - LOAD 'public.geolocation' - SUCCESS
2025-01-10 12:47:45,190 - INFO - LOAD 'public.product_category_name_translation' - SUCCESS
2025-01-10 12:47:47,035 - INFO - LOAD 'public.customers' - SUCCESS
2025-01-10 12:47:47,083 - INFO - LOAD 'public.sellers' - SUCCESS
2025-01-10 12:47:48,231 - INFO - LOAD 'public.products' - SUCCESS
2025-01-10 12:47:50,819 - INFO - LOAD 'public.orders' - SUCCESS
2025-01-10 12:47:53,575 - INFO - LOAD 'public.order_items' - SUCCESS
2025-01-10 12:47:55,474 - INFO - LOAD 'public.order_payments' - SUCCESS
2025-01-10 12:47:57,624 - INFO - LOAD 'public.order_reviews' - SUCCESS
2025-01-10 12:47:57,624 - INFO - LOAD All Tables To DWH-public - SUCCESS
2025-01-10 12:48:06,013 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2025-01-10 12:48:06,024 - INFO - ==================================ENDING LOAD DATA=======================================
2025-01-10 12:48:06,049 - INFO - [pid 1991] Worker Worker(salt=7351372528, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1991) done      Load()
2025-01-10 12:48:06,050 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 12:48:06,054 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2025-01-10 12:48:06,054 - DEBUG - Asking scheduler for work...
2025-01-10 12:48:06,057 - DEBUG - Pending tasks: 1
2025-01-10 12:48:06,057 - INFO - [pid 1991] Worker Worker(salt=7351372528, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1991) running   Transform()
2025-01-10 12:48:06,231 - INFO - Read Transform Query - SUCCESS
2025-01-10 12:48:06,232 - INFO - Connect to DWH - SUCCESS
2025-01-10 12:48:06,233 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2025-01-10 12:48:06,278 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2025-01-10 12:48:06,292 - ERROR - Transform Tables - FAILED
2025-01-10 12:48:06,297 - ERROR - [pid 1991] Worker Worker(salt=7351372528, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1991) failed    Transform()
Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "latitude" does not exist
LINE 7:         latitude,
                ^
DETAIL:  There is a column named "latitude" in table "final", but it cannot be referenced from this part of the query.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/transform.py", line 113, in run
    session.execute(query)
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "latitude" does not exist
LINE 7:         latitude,
                ^
DETAIL:  There is a column named "latitude" in table "final", but it cannot be referenced from this part of the query.

[SQL: MERGE INTO final.dim_customers AS final
USING (
    SELECT 
        customer_id AS customer_nk,
        customer_unique_id,
        customer_zip_code_prefix,
        latitude,
        longitude,
        customer_city,
        customer_state,
        CURRENT_TIMESTAMP AS created_at
    FROM stg.customers
) AS staging

ON final.customer_nk = staging.customer_nk

WHEN MATCHED AND (
    final.customer_zip_code_prefix <> staging.customer_zip_code_prefix OR
    final.customer_city <> staging.customer_city OR
    final.customer_state <> staging.customer_state
) THEN
    UPDATE SET 
        current_flag = 'Expired',
        updated_at = CURRENT_TIMESTAMP

WHEN NOT MATCHED THEN
    INSERT (
        customer_id, 
        customer_nk, 
        customer_unique_id, 
        customer_zip_code_prefix, 
        latitude, 
        longitude,        
        customer_city, 
        customer_state, 
        created_at, 
        updated_at, 
        current_flag
    )
    VALUES (
        gen_random_uuid(),
        staging.customer_nk, 
        staging.customer_unique_id, 
        staging.customer_zip_code_prefix, 
        staging.latitude, 
        staging.longitude,
        staging.customer_city, 
        staging.customer_state, 
        CURRENT_TIMESTAMP, 
        CURRENT_TIMESTAMP, 
        'Current'
    );
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/transform.py", line 208, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2025-01-10 12:48:06,536 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-10 12:48:06,544 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2025-01-10 12:48:06,544 - DEBUG - Asking scheduler for work...
2025-01-10 12:48:06,551 - DEBUG - Done
2025-01-10 12:48:06,551 - DEBUG - There are no more tasks to run at this time
2025-01-10 12:48:06,552 - DEBUG - There are 1 pending tasks possibly being run by other workers
2025-01-10 12:48:06,552 - DEBUG - There are 1 pending tasks unique to this worker
2025-01-10 12:48:06,553 - DEBUG - There are 1 pending tasks last scheduled by this worker
2025-01-10 12:48:06,553 - INFO - Worker Worker(salt=7351372528, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=1991) was stopped. Shutting down Keep-Alive thread
2025-01-10 12:48:06,554 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-12 10:57:18,961 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-12 10:57:19,478 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-12 10:57:20,494 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-12 10:57:20,539 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-12 10:57:22,389 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-12 10:57:23,398 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-12 10:57:24,734 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-12 10:57:26,234 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-12 10:57:26,271 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-12 10:57:26,686 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-12 10:57:26,688 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-12 10:57:26,711 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-12 10:57:26,712 - INFO - [pid 4793] Worker Worker(salt=1894085401, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=4793) done      Extract()
2025-01-12 10:57:26,714 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-12 10:57:26,717 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-12 10:57:26,718 - DEBUG - Asking scheduler for work...
2025-01-12 10:57:26,721 - DEBUG - Pending tasks: 2
2025-01-12 10:57:26,721 - INFO - [pid 4793] Worker Worker(salt=1894085401, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=4793) running   Load()
2025-01-12 10:57:26,765 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-12 10:57:29,528 - INFO - Read Extracted Data - SUCCESS
2025-01-12 10:57:29,529 - INFO - Connect to DWH - SUCCESS
2025-01-12 10:57:29,660 - INFO - Truncate sources Schema in DWH - SUCCESS
2025-01-12 10:57:29,661 - INFO - ==================================STARTING LOAD DATA=======================================
2025-01-12 10:57:30,196 - INFO - LOAD 'public.geolocation' - SUCCESS
2025-01-12 10:57:30,211 - INFO - LOAD 'public.product_category_name_translation' - SUCCESS
2025-01-12 10:57:32,789 - INFO - LOAD 'public.customers' - SUCCESS
2025-01-12 10:57:32,855 - INFO - LOAD 'public.sellers' - SUCCESS
2025-01-12 10:57:34,212 - INFO - LOAD 'public.products' - SUCCESS
2025-01-12 10:57:37,534 - INFO - LOAD 'public.orders' - SUCCESS
2025-01-12 10:57:41,052 - INFO - LOAD 'public.order_items' - SUCCESS
2025-01-12 10:57:43,662 - INFO - LOAD 'public.order_payments' - SUCCESS
2025-01-12 10:57:46,306 - INFO - LOAD 'public.order_reviews' - SUCCESS
2025-01-12 10:57:46,307 - INFO - LOAD All Tables To DWH-public - SUCCESS
2025-01-12 10:57:58,957 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2025-01-12 10:57:58,966 - INFO - ==================================ENDING LOAD DATA=======================================
2025-01-12 10:57:58,993 - INFO - [pid 4793] Worker Worker(salt=1894085401, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=4793) done      Load()
2025-01-12 10:57:58,994 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-12 10:57:58,997 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2025-01-12 10:57:58,998 - DEBUG - Asking scheduler for work...
2025-01-12 10:57:59,002 - DEBUG - Pending tasks: 1
2025-01-12 10:57:59,003 - INFO - [pid 4793] Worker Worker(salt=1894085401, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=4793) running   Transform()
2025-01-12 10:57:59,166 - INFO - Read Transform Query - SUCCESS
2025-01-12 10:57:59,167 - INFO - Connect to DWH - SUCCESS
2025-01-12 10:57:59,167 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2025-01-12 10:57:59,192 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2025-01-12 10:57:59,203 - ERROR - Transform Tables - FAILED
2025-01-12 10:57:59,209 - ERROR - [pid 4793] Worker Worker(salt=1894085401, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=4793) failed    Transform()
Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "latitude" does not exist
LINE 7:         latitude,
                ^
DETAIL:  There is a column named "latitude" in table "final", but it cannot be referenced from this part of the query.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/transform.py", line 113, in run
    session.execute(query)
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "latitude" does not exist
LINE 7:         latitude,
                ^
DETAIL:  There is a column named "latitude" in table "final", but it cannot be referenced from this part of the query.

[SQL: MERGE INTO final.dim_customers AS final
USING (
    SELECT 
        customer_id AS customer_nk,
        customer_unique_id,
        customer_zip_code_prefix,
        latitude,
        longitude,
        customer_city,
        customer_state,
        CURRENT_TIMESTAMP AS created_at
    FROM stg.customers
) AS staging

ON final.customer_nk = staging.customer_nk

WHEN MATCHED AND (
    final.customer_zip_code_prefix <> staging.customer_zip_code_prefix OR
    final.customer_city <> staging.customer_city OR
    final.customer_state <> staging.customer_state
) THEN
    UPDATE SET 
        current_flag = 'Expired',
        updated_at = CURRENT_TIMESTAMP

WHEN NOT MATCHED THEN
    INSERT (
        customer_id, 
        customer_nk, 
        customer_unique_id, 
        customer_zip_code_prefix, 
        latitude, 
        longitude,        
        customer_city, 
        customer_state, 
        created_at, 
        updated_at, 
        current_flag
    )
    VALUES (
        gen_random_uuid(),
        staging.customer_nk, 
        staging.customer_unique_id, 
        staging.customer_zip_code_prefix, 
        staging.latitude, 
        staging.longitude,
        staging.customer_city, 
        staging.customer_state, 
        CURRENT_TIMESTAMP, 
        CURRENT_TIMESTAMP, 
        'Current'
    );
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/transform.py", line 208, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2025-01-12 10:57:59,546 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-12 10:57:59,557 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2025-01-12 10:57:59,557 - DEBUG - Asking scheduler for work...
2025-01-12 10:57:59,560 - DEBUG - Done
2025-01-12 10:57:59,560 - DEBUG - There are no more tasks to run at this time
2025-01-12 10:57:59,560 - DEBUG - There are 1 pending tasks possibly being run by other workers
2025-01-12 10:57:59,561 - DEBUG - There are 1 pending tasks unique to this worker
2025-01-12 10:57:59,561 - DEBUG - There are 1 pending tasks last scheduled by this worker
2025-01-12 10:57:59,561 - INFO - Worker Worker(salt=1894085401, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=4793) was stopped. Shutting down Keep-Alive thread
2025-01-12 10:57:59,563 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-13 09:04:19,895 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-13 09:04:20,400 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-13 09:04:21,288 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-13 09:04:21,336 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-13 09:04:22,964 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-13 09:04:23,783 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-13 09:04:25,165 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-13 09:04:27,030 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-13 09:04:27,073 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-13 09:04:27,575 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-13 09:04:27,577 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-13 09:04:27,612 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-13 09:04:27,614 - INFO - [pid 6730] Worker Worker(salt=585194289, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6730) done      Extract()
2025-01-13 09:04:27,616 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-13 09:04:27,621 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-13 09:04:27,622 - DEBUG - Asking scheduler for work...
2025-01-13 09:04:27,626 - DEBUG - Pending tasks: 2
2025-01-13 09:04:27,627 - INFO - [pid 6730] Worker Worker(salt=585194289, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6730) running   Load()
2025-01-13 09:04:27,679 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-13 09:04:30,286 - INFO - Read Extracted Data - SUCCESS
2025-01-13 09:04:30,287 - INFO - Connect to DWH - SUCCESS
2025-01-13 09:04:30,415 - INFO - Truncate sources Schema in DWH - SUCCESS
2025-01-13 09:04:30,416 - INFO - ==================================STARTING LOAD DATA=======================================
2025-01-13 09:04:30,932 - INFO - LOAD 'public.geolocation' - SUCCESS
2025-01-13 09:04:30,944 - INFO - LOAD 'public.product_category_name_translation' - SUCCESS
2025-01-13 09:04:33,532 - INFO - LOAD 'public.customers' - SUCCESS
2025-01-13 09:04:33,597 - INFO - LOAD 'public.sellers' - SUCCESS
2025-01-13 09:04:35,067 - INFO - LOAD 'public.products' - SUCCESS
2025-01-13 09:04:38,355 - INFO - LOAD 'public.orders' - SUCCESS
2025-01-13 09:04:41,698 - INFO - LOAD 'public.order_items' - SUCCESS
2025-01-13 09:04:44,106 - INFO - LOAD 'public.order_payments' - SUCCESS
2025-01-13 09:04:46,899 - INFO - LOAD 'public.order_reviews' - SUCCESS
2025-01-13 09:04:46,899 - INFO - LOAD All Tables To DWH-public - SUCCESS
2025-01-13 09:04:58,377 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2025-01-13 09:04:58,386 - INFO - ==================================ENDING LOAD DATA=======================================
2025-01-13 09:04:58,412 - INFO - [pid 6730] Worker Worker(salt=585194289, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6730) done      Load()
2025-01-13 09:04:58,413 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-13 09:04:58,417 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2025-01-13 09:04:58,418 - DEBUG - Asking scheduler for work...
2025-01-13 09:04:58,421 - DEBUG - Pending tasks: 1
2025-01-13 09:04:58,422 - INFO - [pid 6730] Worker Worker(salt=585194289, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6730) running   Transform()
2025-01-13 09:04:58,600 - INFO - Read Transform Query - SUCCESS
2025-01-13 09:04:58,601 - INFO - Connect to DWH - SUCCESS
2025-01-13 09:04:58,602 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2025-01-13 09:04:58,634 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2025-01-13 09:04:58,647 - ERROR - Transform Tables - FAILED
2025-01-13 09:04:58,654 - ERROR - [pid 6730] Worker Worker(salt=585194289, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6730) failed    Transform()
Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedFunction: operator does not exist: character varying <> integer
LINE 18:     final.customer_zip_code_prefix <> staging.customer_zip_c...
                                            ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/transform.py", line 113, in run
    session.execute(query)
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedFunction) operator does not exist: character varying <> integer
LINE 18:     final.customer_zip_code_prefix <> staging.customer_zip_c...
                                            ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.

[SQL: MERGE INTO final.dim_customers AS final
USING (
    SELECT 
        customer_id AS customer_nk,
        customer_unique_id,
        customer_zip_code_prefix,
        -- latitude,
        -- longitude,
        customer_city,
        customer_state,
        CURRENT_TIMESTAMP AS created_at
    FROM stg.customers
) AS staging

ON final.customer_nk = staging.customer_nk

WHEN MATCHED AND (
    final.customer_zip_code_prefix <> staging.customer_zip_code_prefix OR
    final.customer_city <> staging.customer_city OR
    final.customer_state <> staging.customer_state
) THEN
    UPDATE SET 
        current_flag = 'Expired',
        updated_at = CURRENT_TIMESTAMP

WHEN NOT MATCHED THEN
    INSERT (
        customer_id, 
        customer_nk, 
        customer_unique_id, 
        customer_zip_code_prefix, 
        -- latitude, 
        -- longitude,        
        customer_city, 
        customer_state, 
        created_at, 
        updated_at, 
        current_flag
    )
    VALUES (
        gen_random_uuid(),
        staging.customer_nk, 
        staging.customer_unique_id, 
        staging.customer_zip_code_prefix, 
        -- staging.latitude, 
        -- staging.longitude,
        staging.customer_city, 
        staging.customer_state, 
        CURRENT_TIMESTAMP, 
        CURRENT_TIMESTAMP, 
        'Current'
    );
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/transform.py", line 208, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2025-01-13 09:04:58,936 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-13 09:04:58,944 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2025-01-13 09:04:58,944 - DEBUG - Asking scheduler for work...
2025-01-13 09:04:58,947 - DEBUG - Done
2025-01-13 09:04:58,947 - DEBUG - There are no more tasks to run at this time
2025-01-13 09:04:58,948 - DEBUG - There are 1 pending tasks possibly being run by other workers
2025-01-13 09:04:58,948 - DEBUG - There are 1 pending tasks unique to this worker
2025-01-13 09:04:58,948 - DEBUG - There are 1 pending tasks last scheduled by this worker
2025-01-13 09:04:58,949 - INFO - Worker Worker(salt=585194289, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6730) was stopped. Shutting down Keep-Alive thread
2025-01-13 09:04:58,950 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-13 09:06:08,408 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-13 09:06:08,672 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-13 09:06:09,684 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-13 09:06:09,724 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-13 09:06:11,238 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-13 09:06:11,990 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-13 09:06:13,326 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-13 09:06:15,009 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-13 09:06:15,049 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-13 09:06:15,450 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-13 09:06:15,452 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-13 09:06:15,474 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-13 09:06:15,476 - INFO - [pid 6755] Worker Worker(salt=9940024117, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6755) done      Extract()
2025-01-13 09:06:15,478 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-13 09:06:15,482 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-13 09:06:15,483 - DEBUG - Asking scheduler for work...
2025-01-13 09:06:15,486 - DEBUG - Pending tasks: 2
2025-01-13 09:06:15,487 - INFO - [pid 6755] Worker Worker(salt=9940024117, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6755) running   Load()
2025-01-13 09:06:15,514 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-13 09:06:17,674 - INFO - Read Extracted Data - SUCCESS
2025-01-13 09:06:17,675 - INFO - Connect to DWH - SUCCESS
2025-01-13 09:06:17,766 - INFO - Truncate sources Schema in DWH - SUCCESS
2025-01-13 09:06:17,766 - INFO - ==================================STARTING LOAD DATA=======================================
2025-01-13 09:06:18,173 - INFO - LOAD 'public.geolocation' - SUCCESS
2025-01-13 09:06:18,183 - INFO - LOAD 'public.product_category_name_translation' - SUCCESS
2025-01-13 09:06:20,239 - INFO - LOAD 'public.customers' - SUCCESS
2025-01-13 09:06:20,347 - INFO - LOAD 'public.sellers' - SUCCESS
2025-01-13 09:06:21,597 - INFO - LOAD 'public.products' - SUCCESS
2025-01-13 09:06:24,449 - INFO - LOAD 'public.orders' - SUCCESS
2025-01-13 09:06:27,549 - INFO - LOAD 'public.order_items' - SUCCESS
2025-01-13 09:06:29,754 - INFO - LOAD 'public.order_payments' - SUCCESS
2025-01-13 09:06:32,178 - INFO - LOAD 'public.order_reviews' - SUCCESS
2025-01-13 09:06:32,179 - INFO - LOAD All Tables To DWH-public - SUCCESS
2025-01-13 09:06:41,901 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2025-01-13 09:06:41,910 - INFO - ==================================ENDING LOAD DATA=======================================
2025-01-13 09:06:41,935 - INFO - [pid 6755] Worker Worker(salt=9940024117, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6755) done      Load()
2025-01-13 09:06:41,936 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-13 09:06:41,939 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2025-01-13 09:06:41,940 - DEBUG - Asking scheduler for work...
2025-01-13 09:06:41,944 - DEBUG - Pending tasks: 1
2025-01-13 09:06:41,944 - INFO - [pid 6755] Worker Worker(salt=9940024117, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6755) running   Transform()
2025-01-13 09:06:42,031 - INFO - Read Transform Query - SUCCESS
2025-01-13 09:06:42,032 - INFO - Connect to DWH - SUCCESS
2025-01-13 09:06:42,033 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2025-01-13 09:06:42,055 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2025-01-13 09:06:42,067 - ERROR - Transform Tables - FAILED
2025-01-13 09:06:42,072 - ERROR - [pid 6755] Worker Worker(salt=9940024117, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6755) failed    Transform()
Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedFunction: operator does not exist: character varying <> integer
LINE 18:     final.customer_zip_code_prefix <> staging.customer_zip_c...
                                            ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/transform.py", line 113, in run
    session.execute(query)
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedFunction) operator does not exist: character varying <> integer
LINE 18:     final.customer_zip_code_prefix <> staging.customer_zip_c...
                                            ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.

[SQL: MERGE INTO final.dim_customers AS final
USING (
    SELECT 
        customer_id AS customer_nk,
        customer_unique_id,
        customer_zip_code_prefix,
        -- latitude,
        -- longitude,
        customer_city,
        customer_state,
        CURRENT_TIMESTAMP AS created_at
    FROM stg.customers
) AS staging

ON final.customer_nk = staging.customer_nk

WHEN MATCHED AND (
    final.customer_zip_code_prefix <> staging.customer_zip_code_prefix OR
    final.customer_city <> staging.customer_city OR
    final.customer_state <> staging.customer_state
) THEN
    UPDATE SET 
        current_flag = 'Expired',
        updated_at = CURRENT_TIMESTAMP

WHEN NOT MATCHED THEN
    INSERT (
        customer_id, 
        customer_nk, 
        customer_unique_id, 
        customer_zip_code_prefix, 
        -- latitude, 
        -- longitude,        
        customer_city, 
        customer_state, 
        created_at, 
        updated_at, 
        current_flag
    )
    VALUES (
        gen_random_uuid(),
        staging.customer_nk, 
        staging.customer_unique_id, 
        staging.customer_zip_code_prefix, 
        -- staging.latitude, 
        -- staging.longitude,
        staging.customer_city, 
        staging.customer_state, 
        CURRENT_TIMESTAMP, 
        CURRENT_TIMESTAMP, 
        'Current'
    );
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/transform.py", line 208, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2025-01-13 09:06:42,316 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-13 09:06:42,323 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2025-01-13 09:06:42,324 - DEBUG - Asking scheduler for work...
2025-01-13 09:06:42,326 - DEBUG - Done
2025-01-13 09:06:42,326 - DEBUG - There are no more tasks to run at this time
2025-01-13 09:06:42,327 - DEBUG - There are 1 pending tasks possibly being run by other workers
2025-01-13 09:06:42,327 - DEBUG - There are 1 pending tasks unique to this worker
2025-01-13 09:06:42,328 - DEBUG - There are 1 pending tasks last scheduled by this worker
2025-01-13 09:06:42,328 - INFO - Worker Worker(salt=9940024117, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6755) was stopped. Shutting down Keep-Alive thread
2025-01-13 09:06:42,329 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-13 09:07:51,205 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-13 09:07:51,438 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-13 09:07:52,226 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-13 09:07:52,261 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-13 09:07:53,797 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-13 09:07:54,486 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-13 09:07:55,657 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-13 09:07:57,066 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-13 09:07:57,106 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-13 09:07:57,513 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-13 09:07:57,515 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-13 09:07:57,544 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-13 09:07:57,546 - INFO - [pid 6776] Worker Worker(salt=2005520220, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6776) done      Extract()
2025-01-13 09:07:57,547 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-13 09:07:57,552 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-13 09:07:57,553 - DEBUG - Asking scheduler for work...
2025-01-13 09:07:57,556 - DEBUG - Pending tasks: 2
2025-01-13 09:07:57,556 - INFO - [pid 6776] Worker Worker(salt=2005520220, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6776) running   Load()
2025-01-13 09:07:57,591 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-13 09:07:59,547 - INFO - Read Extracted Data - SUCCESS
2025-01-13 09:07:59,549 - INFO - Connect to DWH - SUCCESS
2025-01-13 09:07:59,633 - INFO - Truncate sources Schema in DWH - SUCCESS
2025-01-13 09:07:59,633 - INFO - ==================================STARTING LOAD DATA=======================================
2025-01-13 09:08:00,009 - INFO - LOAD 'public.geolocation' - SUCCESS
2025-01-13 09:08:00,019 - INFO - LOAD 'public.product_category_name_translation' - SUCCESS
2025-01-13 09:08:01,887 - INFO - LOAD 'public.customers' - SUCCESS
2025-01-13 09:08:01,937 - INFO - LOAD 'public.sellers' - SUCCESS
2025-01-13 09:08:03,177 - INFO - LOAD 'public.products' - SUCCESS
2025-01-13 09:08:05,935 - INFO - LOAD 'public.orders' - SUCCESS
2025-01-13 09:08:08,892 - INFO - LOAD 'public.order_items' - SUCCESS
2025-01-13 09:08:10,989 - INFO - LOAD 'public.order_payments' - SUCCESS
2025-01-13 09:08:13,341 - INFO - LOAD 'public.order_reviews' - SUCCESS
2025-01-13 09:08:13,343 - INFO - LOAD All Tables To DWH-public - SUCCESS
2025-01-13 09:08:22,869 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2025-01-13 09:08:22,878 - INFO - ==================================ENDING LOAD DATA=======================================
2025-01-13 09:08:22,904 - INFO - [pid 6776] Worker Worker(salt=2005520220, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6776) done      Load()
2025-01-13 09:08:22,905 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-13 09:08:22,909 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2025-01-13 09:08:22,909 - DEBUG - Asking scheduler for work...
2025-01-13 09:08:22,912 - DEBUG - Pending tasks: 1
2025-01-13 09:08:22,912 - INFO - [pid 6776] Worker Worker(salt=2005520220, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6776) running   Transform()
2025-01-13 09:08:22,947 - INFO - Read Transform Query - SUCCESS
2025-01-13 09:08:22,948 - INFO - Connect to DWH - SUCCESS
2025-01-13 09:08:22,949 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2025-01-13 09:08:22,963 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2025-01-13 09:08:22,974 - ERROR - Transform Tables - FAILED
2025-01-13 09:08:22,979 - ERROR - [pid 6776] Worker Worker(salt=2005520220, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6776) failed    Transform()
Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedFunction: operator does not exist: character varying <> integer
LINE 18:     final.customer_zip_code_prefix <> staging.customer_zip_c...
                                            ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/transform.py", line 113, in run
    session.execute(query)
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2306, in execute
    return self._execute_internal(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2200, in _execute_internal
    result = conn.execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1849, in _execute_context
    return self._exec_single_context(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1989, in _exec_single_context
    self._handle_dbapi_exception(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1970, in _exec_single_context
    self.dialect.do_execute(
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedFunction) operator does not exist: character varying <> integer
LINE 18:     final.customer_zip_code_prefix <> staging.customer_zip_c...
                                            ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.

[SQL: MERGE INTO final.dim_customers AS final
USING (
    SELECT 
        customer_id AS customer_nk,
        customer_unique_id,
        customer_zip_code_prefix,
        -- latitude,
        -- longitude,
        customer_city,
        customer_state,
        CURRENT_TIMESTAMP AS created_at
    FROM stg.customers
) AS staging

ON final.customer_nk = staging.customer_nk

WHEN MATCHED AND (
    final.customer_zip_code_prefix <> staging.customer_zip_code_prefix OR
    final.customer_city <> staging.customer_city OR
    final.customer_state <> staging.customer_state
) THEN
    UPDATE SET 
        current_flag = 'Expired',
        updated_at = CURRENT_TIMESTAMP

WHEN NOT MATCHED THEN
    INSERT (
        customer_id, 
        customer_nk, 
        customer_unique_id, 
        customer_zip_code_prefix, 
        -- latitude, 
        -- longitude,        
        customer_city, 
        customer_state, 
        created_at, 
        updated_at, 
        current_flag
    )
    VALUES (
        gen_random_uuid(),
        staging.customer_nk, 
        staging.customer_unique_id, 
        staging.customer_zip_code_prefix, 
        -- staging.latitude, 
        -- staging.longitude,
        staging.customer_city, 
        staging.customer_state, 
        CURRENT_TIMESTAMP, 
        CURRENT_TIMESTAMP, 
        'Current'
    );
]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/transform.py", line 208, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2025-01-13 09:08:23,071 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-13 09:08:23,077 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2025-01-13 09:08:23,078 - DEBUG - Asking scheduler for work...
2025-01-13 09:08:23,080 - DEBUG - Done
2025-01-13 09:08:23,081 - DEBUG - There are no more tasks to run at this time
2025-01-13 09:08:23,081 - DEBUG - There are 1 pending tasks possibly being run by other workers
2025-01-13 09:08:23,081 - DEBUG - There are 1 pending tasks last scheduled by this worker
2025-01-13 09:08:23,083 - INFO - Worker Worker(salt=2005520220, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6776) was stopped. Shutting down Keep-Alive thread
2025-01-13 09:08:23,084 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2025-01-13 09:11:04,497 - INFO - ==================================STARTING EXTRACT DATA=======================================
2025-01-13 09:11:04,779 - INFO - EXTRACT 'public.geolocation' - SUCCESS.
2025-01-13 09:11:05,790 - INFO - EXTRACT 'public.customers' - SUCCESS.
2025-01-13 09:11:05,829 - INFO - EXTRACT 'public.sellers' - SUCCESS.
2025-01-13 09:11:07,277 - INFO - EXTRACT 'public.order_items' - SUCCESS.
2025-01-13 09:11:07,969 - INFO - EXTRACT 'public.order_payments' - SUCCESS.
2025-01-13 09:11:09,111 - INFO - EXTRACT 'public.order_reviews' - SUCCESS.
2025-01-13 09:11:10,752 - INFO - EXTRACT 'public.orders' - SUCCESS.
2025-01-13 09:11:10,787 - INFO - EXTRACT 'public.product_category_name_translation' - SUCCESS.
2025-01-13 09:11:11,182 - INFO - EXTRACT 'public.products' - SUCCESS.
2025-01-13 09:11:11,184 - INFO - Extract All Tables From Sources - SUCCESS
2025-01-13 09:11:11,201 - INFO - ==================================ENDING EXTRACT DATA=======================================
2025-01-13 09:11:11,203 - INFO - [pid 6798] Worker Worker(salt=9716387925, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6798) done      Extract()
2025-01-13 09:11:11,204 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-13 09:11:11,207 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2025-01-13 09:11:11,208 - DEBUG - Asking scheduler for work...
2025-01-13 09:11:11,212 - DEBUG - Pending tasks: 2
2025-01-13 09:11:11,213 - INFO - [pid 6798] Worker Worker(salt=9716387925, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6798) running   Load()
2025-01-13 09:11:11,250 - ERROR - truncate query TRUNCATE TABLE public.customers CASCADE;
TRUNCATE TABLE public.geolocation CASCADE;
TRUNCATE TABLE public.order_items CASCADE;
TRUNCATE TABLE public.order_payments CASCADE;
TRUNCATE TABLE public.order_reviews CASCADE;
TRUNCATE TABLE public.orders CASCADE;
TRUNCATE TABLE public.product_category_name_translation CASCADE;
TRUNCATE TABLE public.products CASCADE;
TRUNCATE TABLE public.sellers CASCADE;
2025-01-13 09:11:13,380 - INFO - Read Extracted Data - SUCCESS
2025-01-13 09:11:13,381 - INFO - Connect to DWH - SUCCESS
2025-01-13 09:11:13,466 - INFO - Truncate sources Schema in DWH - SUCCESS
2025-01-13 09:11:13,467 - INFO - ==================================STARTING LOAD DATA=======================================
2025-01-13 09:11:13,851 - INFO - LOAD 'public.geolocation' - SUCCESS
2025-01-13 09:11:13,861 - INFO - LOAD 'public.product_category_name_translation' - SUCCESS
2025-01-13 09:11:15,825 - INFO - LOAD 'public.customers' - SUCCESS
2025-01-13 09:11:15,881 - INFO - LOAD 'public.sellers' - SUCCESS
2025-01-13 09:11:17,096 - INFO - LOAD 'public.products' - SUCCESS
2025-01-13 09:11:20,274 - INFO - LOAD 'public.orders' - SUCCESS
2025-01-13 09:11:23,092 - INFO - LOAD 'public.order_items' - SUCCESS
2025-01-13 09:11:25,173 - INFO - LOAD 'public.order_payments' - SUCCESS
2025-01-13 09:11:27,496 - INFO - LOAD 'public.order_reviews' - SUCCESS
2025-01-13 09:11:27,497 - INFO - LOAD All Tables To DWH-public - SUCCESS
2025-01-13 09:11:36,102 - INFO - LOAD All Tables To DWH-Staging - SUCCESS
2025-01-13 09:11:36,108 - INFO - ==================================ENDING LOAD DATA=======================================
2025-01-13 09:11:36,135 - INFO - [pid 6798] Worker Worker(salt=9716387925, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6798) done      Load()
2025-01-13 09:11:36,136 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-13 09:11:36,139 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2025-01-13 09:11:36,140 - DEBUG - Asking scheduler for work...
2025-01-13 09:11:36,142 - DEBUG - Pending tasks: 1
2025-01-13 09:11:36,143 - INFO - [pid 6798] Worker Worker(salt=9716387925, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6798) running   Transform()
2025-01-13 09:11:36,214 - INFO - Read Transform Query - SUCCESS
2025-01-13 09:11:36,216 - INFO - Connect to DWH - SUCCESS
2025-01-13 09:11:36,217 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2025-01-13 09:11:37,094 - INFO - Transform to 'final.dim_customers' - SUCCESS
2025-01-13 09:11:37,095 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2025-01-13 09:11:37,107 - ERROR - Transform Tables - FAILED
2025-01-13 09:11:37,112 - ERROR - [pid 6798] Worker Worker(salt=9716387925, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6798) failed    Transform()
Traceback (most recent call last):
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/transform.py", line 117, in run
    query = sqlalchemy.text(dim_order_items_query)
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/sql/_elements_constructors.py", line 1640, in text
    return TextClause(text)
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 2295, in __init__
    self.text = self._bind_params_regex.sub(repl, text)
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/mnt/d/coding/training/Data_Warehouse/Week_05/dataset-olist/.venvu/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/mnt/d/Coding/Training/Data_Warehouse/Week_05/dataset-olist/pipeline/transform.py", line 208, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2025-01-13 09:11:37,254 - DEBUG - 1 running tasks, waiting for next task to finish
2025-01-13 09:11:37,261 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2025-01-13 09:11:37,262 - DEBUG - Asking scheduler for work...
2025-01-13 09:11:37,266 - DEBUG - Done
2025-01-13 09:11:37,266 - DEBUG - There are no more tasks to run at this time
2025-01-13 09:11:37,267 - DEBUG - There are 1 pending tasks possibly being run by other workers
2025-01-13 09:11:37,267 - DEBUG - There are 1 pending tasks unique to this worker
2025-01-13 09:11:37,268 - DEBUG - There are 1 pending tasks last scheduled by this worker
2025-01-13 09:11:37,269 - INFO - Worker Worker(salt=9716387925, workers=1, host=DESKTOP-MDVFE7I, username=user, pid=6798) was stopped. Shutting down Keep-Alive thread
2025-01-13 09:11:37,270 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

